{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from deepalign import Dataset\n",
    "from deepalign import fs\n",
    "from deepalign.alignments import ALIGNERS\n",
    "from deepalign.alignments.confnet import ConfNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the evaluation, we are caching all results. You will have received these cache files with the download of the GitHub release. In case you want to run your own experiments, this is the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aligner(model_file, dataset):\n",
    "    if 'confnet' in model_file.ad:\n",
    "        aligner = ALIGNERS[model_file.ad[:-2]](dataset,\n",
    "                                               use_case_attributes=model_file.use_case_attributes,\n",
    "                                               use_event_attributes=model_file.use_event_attributes)\n",
    "    else:\n",
    "        aligner = ALIGNERS[model_file.ad]()\n",
    "    aligner.load(str(fs.MODEL_DIR / model_file.name))\n",
    "    return aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625e950bc3ee40128874579f92a6e5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 651/651 [00:17<00:00, 37.05it/s]\n",
      "paper-0.3-4: 100%|██████████| 651/651 [00:04<00:00, 156.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "synthetic = ['paper', 'p2p', 'small', 'medium', 'large', 'huge', 'gigantic', 'wide']\n",
    "\n",
    "models = sorted(list(set([f.name.replace('_forward', '').replace('_backward', '')\n",
    "                          for f in fs.get_aligner_files()])))\n",
    "\n",
    "models = [m for m in models if not (fs.RESULT_DIR / (fs.ModelFile(m).name + '.h5')).exists()]\n",
    "\n",
    "for model in tqdm(models):\n",
    "    model_file = fs.AlignerFile(model)\n",
    "    dataset = Dataset(model_file.event_log_name,\n",
    "                      use_case_attributes=model_file.use_case_attributes,\n",
    "                      use_event_attributes=model_file.use_event_attributes)\n",
    "    aligner = get_aligner(model_file, dataset)\n",
    "\n",
    "    if isinstance(aligner, ConfNet):\n",
    "        alignments, beams, costs = aligner.batch_align(dataset, batch_size=5000)\n",
    "    else:\n",
    "        try:\n",
    "            alignments, beams, costs = aligner.align(dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    with h5py.File(str(fs.RESULT_DIR / (model_file.name + '.h5')), 'w') as file:\n",
    "        file.create_dataset('alignments', data=alignments, compression=\"gzip\", compression_opts=9)\n",
    "        file.create_dataset('beams', data=beams, compression=\"gzip\", compression_opts=9)\n",
    "        file.create_dataset('costs', data=costs, compression=\"gzip\", compression_opts=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
