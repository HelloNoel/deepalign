{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pretrained neural networks are available as part of the download from notebook [2. Dataset Generation](2.%20Dataset%20Generation.ipynb). If you haven't downloaded the models from the release yet, we suggest that you do now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to train your own models, here is the code to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from deepalign import Dataset\n",
    "from deepalign import fs\n",
    "from deepalign.alignments import ConfNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get all dataset filenames using this helper method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = sorted([f.name for f in fs.get_event_log_files() if 'paper' not in f.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a ConfNet (name of the RNN model) model for each of the datasets using the following for loop. It will create a version of ConfNet with no attributes `(0, 0)`, only case attributes `(0, 1)`, only event attributes `(1, 0)`, and both `(1, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in datasets:\n",
    "    for ea, ca in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "        start_time = arrow.now()\n",
    "        dataset = Dataset(dataset_name, use_case_attributes=ca, use_event_attributes=ea)\n",
    "        if ca and dataset.num_case_attributes == 0:\n",
    "            continue\n",
    "        confnet = ConfNet(dataset, use_case_attributes=ca, use_event_attributes=ea)\n",
    "        confnet.fit(dataset, batch_size=100, epochs=1, validation_split=0.1,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)])\n",
    "        confnet.save(\n",
    "            str(fs.MODEL_DIR / f'{dataset_name}_{confnet.identifier}_{start_time.format(fs.DATE_FORMAT)}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepalign.alignments.processmining import OptimalCostAligner\n",
    "from deepalign.alignments.processmining import HeuristicsMinerAligner\n",
    "from deepalign.alignments.processmining import InductiveMinerAligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = sorted([f.name for f in fs.get_event_log_files() if 'paper' not in f.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligners = [OptimalCostAligner, HeuristicsMinerAligner, InductiveMinerAligner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aligner_class in tqdm(aligners):\n",
    "    for dataset_name in tqdm(datasets):\n",
    "        dataset = Dataset(dataset_name)\n",
    "        aligner = aligner_class()\n",
    "        aligner.fit(dataset)\n",
    "        file_name = f'{dataset_name}_{aligner.abbreviation}'\n",
    "        aligner.save(file_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6d4c3a640139fa1d60909bdb20efa3e73b479a482238243b6e74d44f71969d7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('deepalign')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
