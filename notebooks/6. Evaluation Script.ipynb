{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also have received the `evaluation.xlsx` file as part of the download. This is the code to create your own evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from deepalign import Dataset\n",
    "from deepalign import fs\n",
    "from deepalign.utils import gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignmnets(file):\n",
    "    with h5py.File(file.result_file, 'r') as file:\n",
    "        alignments = np.array(file['alignments'])\n",
    "        x = np.array(file['beams'])\n",
    "        costs = np.array(file['costs'])\n",
    "    return alignments, x, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate for each case if any of the `k` beams matches the ground truth exactly and calculate the accuracy. This will give us five values, top-1, top-2, and so on. Top-3 accuracy indicates that at least one of the top-3 beams is correct.\n",
    "\n",
    "Optimality is only calculated for alignments that match the ground truth. An alignment is optimal if its cost matches the optimal costs from the ground truth.\n",
    "\n",
    "The error is only calculated for alignments that do not match the ground truth. We use the `editdistance` package to calculate the distance between the corrected case and the ground truth case (without the empty moves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted([fs.AlignerFile(f) for f in fs.CONFNET_RESULT_DIR.glob('*')], key=lambda f: f.event_log_name)\n",
    "\n",
    "frames = []\n",
    "dataset = None\n",
    "for file in tqdm(results):\n",
    "    if dataset is None or dataset.dataset_name != file.event_log_name:\n",
    "        dataset = Dataset(file.event_log_name)\n",
    "\n",
    "    alignments, x, costs = get_alignmnets(file)\n",
    "\n",
    "    y = dataset.correct_features[0]\n",
    "    y = np.pad(y, ((0, 0), (0, x.shape[-1] - y.shape[1])))\n",
    "\n",
    "    match = np.all(x == y[:, None], -1)\n",
    "\n",
    "    correct = match\n",
    "    incorrect = ~match\n",
    "    optimal_costs = costs == dataset.alignments[1][:, None]\n",
    "    optimal_alignment = np.logical_and(optimal_costs, correct)\n",
    "\n",
    "    distances = np.array([[editdistance.distance(a, _b) for _b in b] for a, b in zip(y, x)])\n",
    "\n",
    "    for label in dataset.unique_text_labels:\n",
    "        label_type = 'Normal' if label == 'Normal' else 'Anomalous'\n",
    "        dataset_type = 'Synthetic'\n",
    "        indices = np.where(dataset.text_labels == label)[0]\n",
    "        for k in range(1, alignments.shape[1] + 1, 1):\n",
    "            cor = correct[indices][:, :k].any(-1)\n",
    "            inc = ~cor\n",
    "            opt = optimal_alignment[indices][cor][:, :k].any(-1)\n",
    "            dist = gather(distances[indices][inc], incorrect[indices][:, :k].argmax(-1)[inc][:, None])\n",
    "\n",
    "            evaluation = [\n",
    "                file.name, file.event_log_name, file.ad, file.model, file.p, file.id, k, label, label_type,\n",
    "                dataset_type,\n",
    "                cor.sum(), inc.sum(), opt.sum(), cor.mean(), opt.mean(), dist.mean()\n",
    "            ]\n",
    "\n",
    "            frames.append(evaluation)\n",
    "\n",
    "columns = ['file_name', 'dataset', 'algorithm', 'process_model', 'p', 'dataset_id', 'k', 'label', 'binary_label',\n",
    "           'dataset_type', 'num_correct', 'num_incorrect', 'num_optimal', 'accuracy', 'optimality', 'error']\n",
    "\n",
    "evaluation = pd.DataFrame(frames, columns=columns)\n",
    "\n",
    "evaluation.to_excel(str(fs.OUT_DIR / 'evaluation-real.xlsx'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
